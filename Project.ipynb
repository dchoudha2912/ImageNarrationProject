{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb533801",
   "metadata": {},
   "source": [
    "# Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3196192d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "input_img = Image.open(\"images/Image_3.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73f964d",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14f9bde",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "objectDetectionModel = pipeline(task = \"object-detection\", model = \"facebook/detr-resnet-50\")\n",
    "\n",
    "objectsDetected = objectDetectionModel(input_img)\n",
    "\n",
    "# feature extraction from object detection output.\n",
    "\n",
    "label_counts = {}\n",
    "for item in objectsDetected:\n",
    "    label = item['label']\n",
    "    label_counts[label] = label_counts.get(label, 0) + 1\n",
    "\n",
    "labels = (label_counts.keys())\n",
    "\n",
    "textModelInput = \"There are \"\n",
    "\n",
    "for item in labels:\n",
    "    count_label = label_counts[item]\n",
    "    textModelInput += str(count_label)\n",
    "    textModelInput += \" \"\n",
    "    textModelInput += item + \",\"\n",
    "\n",
    "textModelInput += \" in this image.\"\n",
    "\n",
    "# text summarization from feature extraction output.\n",
    "\n",
    "# Specify the inference task\n",
    "generator = pipeline(\n",
    "    task=\"text-generation\",\n",
    "    model=\"Qwen/Qwen3-0.6B\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "response = generator(textModelInput, max_length=200)\n",
    "\n",
    "inputforAudioModel = \"\"\n",
    "for value in response:\n",
    "    allKeys = value.keys()\n",
    "    for key in allKeys:\n",
    "        inputforAudioModel = value[key]\n",
    "\n",
    "# passing text generator output to audio model.\n",
    "\n",
    "narrator = pipeline(\n",
    "    task=\"text-to-speech\",\n",
    "    model=\"suno/bark-small\",\n",
    ")\n",
    "\n",
    "naratorOutput = narrator(inputforAudioModel);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f10983",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34209c0b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Audio as IPythonAudio\n",
    "\n",
    "IPythonAudio(\n",
    "    naratorOutput[\"audio\"],\n",
    "    rate=naratorOutput[\"sampling_rate\"]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
